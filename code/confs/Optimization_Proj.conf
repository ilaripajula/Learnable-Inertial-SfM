exp_name = Optimization_Proj
#random_seed = 0
dataset
{
    use_gt = False
    calibrated = False
    scan = 120_frame_test
    scans_list = ["Alcatraz Courtyard", "Pumpkin", "Alcatraz Water Tower", "Folke Filbyter", "Gustav Vasa", "Dino 319",
    "Park Gate", "Skansen Kronan", "Smolny Cathedral","Sri Thendayuthapani", "Toronto University", "House", "De Guerre",
    "Golden Statue", "Dino 4983", "Tsar Nikolai I", "Buddah Tooth", "Cherub", "Drinking Fountain", "Jonas Ahls",
    "Porta San Donato", "Nijo", "Corridor", "Sphinx", "Dome", "Doge Palace", "East Indiaman Goteborg","GustavIIAdolf",
    "Lund University Sphinx","Pantheon Paris","Plaza De Armas Santiago",
    "Some Cathedral In Barcelona","Sri Mariamman Singapore","Sri Veeramakaliamman Singapore",
    "Thian Hook Keng Temple Singapore","Urban II","Alcatraz West Side Gardens",
    "Skansen Lejonet", "Basilica Di San Petronio", "Buddah Statue", "Kings College"]
}
model
{
    type = SetOfSet.SetOfSetNet
    num_features = 256
    num_blocks = 1
    block_size = 3
    use_skip = False
    normalize_output = Differentiable Chirality
    multires = 0
}
train
{
    lr = 1e-4
    num_of_epochs = 1e+5
    scheduler_milestone = [50000, 70000, 90000]
    gamma = 0.1
    eval_intervals = 5000
}
loss
{
    func = ESFMLoss
    infinity_pts_margin = 1e-4
    normalize_grad = True
    hinge_loss = True
    hinge_loss_weight = 1
}
ba
{
run_ba = True
repeat=True
triangulation=False # If repeat, the first time is from our points and the second from triangulation
only_last_eval = True
}


